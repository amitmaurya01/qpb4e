# -*- coding: utf-8 -*-
"""Chapter_10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/nceder/qpb4e/blob/main/code/Chapter%2010/Chapter_10.ipynb

# 10 Modules and scoping rules

# 10.2 A first module
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile mymath.py
# """mymath - our example math module"""
# pi = 3.14159
# def area(r):
#     """area(r): return the area of a circle with radius r."""
#     return(pi * r * r)

pi

area(2)

import mymath
pi

mymath.pi

mymath.area(2)

mymath.__doc__

mymath.area.__doc__

from mymath import pi
pi

area(2)

import mymath, importlib
importlib.reload(mymath)

"""# 10.3 The import statement"""

from mymath import *

"""# 10.4 The module search path"""

import sys
sys.path

"""# 10.5 Private names in modules"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile modtest.py(
# """modtest: our test module"""
# def f(x):
#     return x
# def _g(x):
#     return x
# a = 4
# _b = 2

from modtest import *
f(3)

_g(3)

a

_b

import modtest
modtest._b

from modtest import _g
_g(5)

"""# 10.6 Library and third-party modules

### Quick Check: Modules
Suppose that you have a module called `new_math` that contains a function called `new_divide`. What are the ways that you might import and then use that function? What are the pros and cons of each method?

```python
import new_math
new_math.new_divide(...)
```
**This solution is often preferred because there won’t be a clash between any identifiers in new_module and the importing namespace. This solution is less convenient to type, however.**

```python
from new_math import new_divide
new_divide(...)
```
**This version is more convenient to use but increases the chance of name clashes between identifiers in the module and the importing namespace.**

Suppose that the new_math module contains a function called `_helper_mat-h()`. How will the underscore character affect the way that `_helper_math()` is imported?

**It won’t be imported if you use `from new_math import*`**

# 10.7 Python scoping rules and namespaces
"""

locals()

globals()

z = 2
import math
from cmath import cos
globals()

locals()

math.ceil(3.4)

del z, math, cos

math.ceil(3.4)

import math
math.ceil(3.4)

def f(x):

    print("Entry local: ", locals())
    y = x
    print("Exit local: ", locals())

z = 2

f(z)

# Commented out IPython magic to ensure Python compatibility.
# %%writefile scopetest.py
# """scopetest: our scope test module"""
# v = 6
# def f(x):
#     """f: scope test function"""
#     print("global: ", list(globals().keys()))
#     print("entry local:", locals())
#     y = x
#     w = v
#     print("exit local:", locals().keys())

import scopetest
z = 2
scopetest.f(z)

"""## 10.7.1 The built-in namespace"""

dir(__builtins__)

print(max.__doc__)

list("Peyto Lake")

list = [1, 3, 5, 7]
list("Peyto Lake")

import mymath
mymath = mymath.area
mymath.pi

del list
list("Peyto Lake")

import mymath
mymath.pi

x1 = 6
xl = x1 - 2
x1

dir()

"""### Quick Check: Namespaces and scope
Consider a variable width that's in the module `make_window.py`. In which of the following contexts is width in scope?:

 1. within the module itself
 2. inside the `resize()` function in the module
 3. within the script that imported the `make_window.py` module

 **A and B but not C**

# Lab 10: Create a module
Package the functions created at the end of chapter 9 as a standalone module. Although you can include code to run the module as the main program, the goal should be for the functions to be completely usable from another script. To test, create a new Jupyter notebook and write the code to load and use the module to get the same results as the code in Chapter 9.
"""

!wget https://raw.githubusercontent.com/nceder/qpb4e/main/code/Chapter%2006/moby_01.txt &> null  && echo Downloaded

with open("text_processing_author.py", "w") as f:
    f.write(r'''
# Author's version
import string
punct = str.maketrans('', '', string.punctuation)

def clean_line(line):
    """changes case and removes punctuation"""
    # make all one case
    cleaned_line = line.lower()

    # remove punctuation
    cleaned_line = cleaned_line.translate(punct)
    return cleaned_line


def get_words(line):
    """splits line into words, and rejoins with newlines"""
    words = line.split()
    return "\n".join(words) + "\n"


def count_words(words):
    """takes list of cleaned words, returns count dictionary"""
    word_count = {}
    for word in words:
        count = word_count.setdefault(word, 0)
        word_count[word] += 1
    return word_count


def word_stats(word_count):
    """Takes word count dictionary and returns top and bottom five entries"""
    word_list = list(word_count.items())
    word_list.sort(key=lambda x: x[1])
    least_common = word_list[:5]
    most_common = word_list[-1:-6:-1]
    return most_common, least_common
'''
    )

import text_processing_author


with open("moby_01.txt") as infile, open("moby_01_clean.txt", "w") as outfile:
    for line in infile:
        cleaned_line = text_processing_author.clean_line(line)

        cleaned_words = text_processing_author.get_words(cleaned_line)

        # write all words for line
        outfile.write(cleaned_words)

moby_words = []
with open('moby_01_clean.txt') as infile:
    for word in infile:
        if word.strip():
            moby_words.append(word.strip())


word_count = text_processing_author.count_words(moby_words)

most, least = text_processing_author.word_stats(word_count)
print("Most common words:")
for word in most:
    print(word)
print("\nLeast common words:")
for word in least:
    print(word)

# refactored code from Copilot
import string

def clean_line(line):
    # Convert the line to lowercase
    line = line.lower()

    # Remove punctuation from the line
    line = line.translate(str.maketrans('', '', string.punctuation))

    return line

def write_words_to_file(words, output_file):
    # Write each word to the output file
    for word in words:
        output_file.write(word + '\n')

def count_word_occurrences(words):
    # Count the occurrences of each word using a dictionary
    word_counts = {}
    for word in words:
        if word in word_counts:
            word_counts[word] += 1
        else:
            word_counts[word] = 1

    return word_counts

def print_common_words(word_counts, n):
    # Sort the word counts in descending order
    sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)

    # Print the n most common words and their occurrences
    print(f"{n} most common words:")
    for word, count in sorted_word_counts[:n]:
        print(f"{word}: {count}")

def print_least_common_words(word_counts, n):
    # Sort the word counts in descending order
    sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)

    # Print the n least common words and their occurrences
    print(f"{n} least common words:")
    for word, count in sorted_word_counts[-n:]:
        print(f"{word}: {count}")

def process_file(input_file_path, output_file_path):
    # Open the input file for reading
    with open(input_file_path, 'r') as input_file:
        # Open the output file for writing
        with open(output_file_path, 'w') as output_file:
            # Iterate over each line in the input file
            for line in input_file:
                # Clean the line
                cleaned_line = clean_line(line)

                # Split the line into words
                words = cleaned_line.split()

                # Write the words to the output file
                write_words_to_file(words, output_file)

def main():
    input_file_path = 'moby_01.txt'
    output_file_path = 'moby_01_clean.txt'

    # Process the file
    process_file(input_file_path, output_file_path)

    # Open the file
    with open(output_file_path, 'r') as file:
        # Read the file content
        content = file.read()

    # Split the content into words
    words = content.split()

    # Count word occurrences
    word_counts = count_word_occurrences(words)

    # Print the five most common words and their occurrences
    print_common_words(word_counts, 5)

    # Print the five least common words and their occurrences
    print_least_common_words(word_counts, 5)

if __name__ == "__main__":
    main()

# Generated by colaboratory
# prompt: Package the functions in the cell above as a standalone module so that
#         the module can be used by other code. Then write the code to use the
#         module to achieve the same result as the cell above.

# Save the functions as a module named "text_processing.py"
with open("text_processing.py", "w") as f:
    f.write(r"""
def clean_line(line):
    # Convert the line to lowercase
    line = line.lower()

    # Remove punctuation from the line
    line = line.translate(str.maketrans('', '', string.punctuation))

    return line

def write_words_to_file(words, output_file):
    # Write each word to the output file
    for word in words:
        output_file.write(word + '\n')

def count_word_occurrences(words):
    # Count the occurrences of each word using a dictionary
    word_counts = {}
    for word in words:
        if word in word_counts:
            word_counts[word] += 1
        else:
            word_counts[word] = 1

    return word_counts

def print_common_words(word_counts, n):
    # Sort the word counts in descending order
    sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)

    # Print the n most common words and their occurrences
    print(f"{n} most common words:")
    for word, count in sorted_word_counts[:n]:
        print(f"{word}: {count}")

def print_least_common_words(word_counts, n):
    # Sort the word counts in descending order
    sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)

    # Print the n least common words and their occurrences
    print(f"{n} least common words:")
    for word, count in sorted_word_counts[-n:]:
        print(f"{word}: {count}")

def process_file(input_file_path, output_file_path):
    # Open the input file for reading
    with open(input_file_path, 'r') as input_file:
        # Open the output file for writing
        with open(output_file_path, 'w') as output_file:
            # Iterate over each line in the input file
            for line in input_file:
                # Clean the line
                cleaned_line = clean_line(line)

                # Split the line into words
                words = cleaned_line.split()

                # Write the words to the output file
                write_words_to_file(words, output_file)
""")

# Use the module
import text_processing

input_file_path = 'moby_01.txt'
output_file_path = 'moby_01_clean.txt'

# Process the file
text_processing.process_file(input_file_path, output_file_path)

# Open the file
with open(output_file_path, 'r') as file:
    # Read the file content
    content = file.read()

# Split the content into words
words = content.split()

# Count word occurrences
word_counts = text_processing.count_word_occurrences(words)

# Print the five most common words and their occurrences
text_processing.print_common_words(word_counts, 5)

# Print the five least common words and their occurrences
text_processing.print_least_common_words(word_counts, 5)

"""* add r before file string (otherwise \\n in line 14 is written as linefeed).
* import string in line 1 of module.

### Copilot version
"""

# Copilot version
# FILENAME: word_processing.py

import string

def clean_line(line):
    line = line.lower()
    line = line.translate(str.maketrans('', '', string.punctuation))
    return line

def write_words_to_file(words, output_file):
    for word in words:
        output_file.write(word + '\n')

def count_word_occurrences(words):
    word_counts = {}
    for word in words:
        if word in word_counts:
            word_counts[word] += 1
        else:
            word_counts[word] = 1
    return word_counts

def print_common_words(word_counts, n):
    sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)
    print(f"{n} most common words:")
    for word, count in sorted_word_counts[:n]:
        print(f"{word}: {count}")

def print_least_common_words(word_counts, n):
    sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)
    print(f"{n} least common words:")
    for word, count in sorted_word_counts[-n:]:
        print(f"{word}: {count}")

def process_file(input_file_path, output_file_path):
    with open(input_file_path, 'r') as input_file:
        with open(output_file_path, 'w') as output_file:
            for line in input_file:
                cleaned_line = clean_line(line)
                words = cleaned_line.split()
                write_words_to_file(words, output_file)

# FILENAME: main.py

import word_processing

input_file_path = "path_to_input_file"
output_file_path = "path_to_output_file"

# Process the file
word_processing.process_file(input_file_path, output_file_path)

# Count word occurrences
with open(output_file_path, 'r') as output_file:
    words = output_file.read().split()
    word_counts = word_processing.count_word_occurrences(words)

# Print common and least common words
word_processing.print_common_words(word_counts, 10)
word_processing.print_least_common_words(word_counts, 10)

# FILENAME: main.py

import word_processing

input_file_path = "moby_01.txt"
output_file_path = "moby_01_clean.txt"

# Process the file
word_processing.process_file(input_file_path, output_file_path)

# Count word occurrences
with open(output_file_path, 'r') as output_file:
    words = output_file.read().split()
    word_counts = word_processing.count_word_occurrences(words)

# Print common and least common words
word_processing.print_common_words(word_counts, 10)
word_processing.print_least_common_words(word_counts, 10)

