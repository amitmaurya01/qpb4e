# -*- coding: utf-8 -*-
"""Chapter_23.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/nceder/qpb4e/blob/main/code/Chapter%2023/Chapter_23.ipynb

# 23 Saving Data

# 23.2 SQLite: Using the sqlite3 database
"""

import sqlite3
conn = sqlite3.connect("datafile.db")

cursor = conn.cursor()
cursor

cursor.execute("create table people (id integer primary key, name text, count integer)")
cursor.execute("insert into people (name, count) values ('Bob', 1)")
cursor.execute("insert into people (name, count) values (?, ?)",
               ("Jill", 15))
conn.commit()

cursor.execute("insert into people (name, count) values (:username, :usercount)",
                  {"username": "Joe", "usercount": 10})

result = cursor.execute("select * from people")
print(result.fetchall())

result = cursor.execute("select * from people where name like :name",
                        {"name": "bob"})
print(result.fetchall())

cursor.execute("update people set count=? where name=?", (20, "Jill"))
result = cursor.execute("select * from people")
print(result.fetchall())

result = cursor.execute("select * from people")
for row in result:
    print(row)

cursor.execute("update people set count=? where name=?", (20, "Jill"))
conn.commit()
conn.close()

"""### TRY This: Creating and modifying Tables
Using sqlite3, write the code that creates a database table for the Illinois weather data you loaded from a flat file in section 22.2. Suppose that you have similar data for more states and want to store more information about the states themselves. How could you modify your database to use a related table to store the state information?
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile temp_data_01.csv
# "Notes","State","State Code","Month Day, Year","Month Day, Year Code",Avg Daily Max Air Temperature (F),Record Count for Daily Max Air Temp (F),Min Temp for Daily Max Air Temp (F),Max Temp for Daily Max Air Temp (F),Avg Daily Max Heat Index (F),Record Count for Daily Max Heat Index (F),Min for Daily Max Heat Index (F),Max for Daily Max Heat Index (F),Daily Max Heat Index (F) % Coverage
# 
# ,"Illinois","17","Jan 01, 1979","1979/01/01",17.48,994,6.00,30.50,Missing,0,Missing,Missing,0.00%
# ,"Illinois","17","Jan 02, 1979","1979/01/02",4.64,994,-6.40,15.80,Missing,0,Missing,Missing,0.00%
# ,"Illinois","17","Jan 03, 1979","1979/01/03",11.05,994,-0.70,24.70,Missing,0,Missing,Missing,0.00%
# ,"Illinois","17","Jan 04, 1979","1979/01/04",9.51,994,0.20,27.60,Missing,0,Missing,Missing,0.00%
# ,"Illinois","17","May 15, 1979","1979/05/15",68.42,994,61.00,75.10,Missing,0,Missing,Missing,0.00%
# ,"Illinois","17","May 16, 1979","1979/05/16",70.29,994,63.40,73.50,Missing,0,Missing,Missing,0.00%
# ,"Illinois","17","May 17, 1979","1979/05/17",75.34,994,64.00,80.50,82.60,2,82.40,82.80,0.20%
# ,"Illinois","17","May 18, 1979","1979/05/18",79.13,994,75.50,82.10,81.42,349,80.20,83.40,35.11%
# ,"Illinois","17","May 19, 1979","1979/05/19",74.94,994,66.90,83.10,82.87,78,81.60,85.20,7.85%
#



# @title
import sqlite3
conn = sqlite3.connect("datafile.db")

cursor = conn.cursor()

cursor.execute("""create table weather (id integer primary key,
              state text, state_code text,
              year_text text, year_code text, avg_max_temp real,  max_temp_count integer,
              max_temp_low real, max_temp_high real,
              heat_index real, heat_index_count integer,
              heat_index_low real, heat_index_high real,
              heat_index_coverage text)
              """)
conn.commit()


# load data from file
import csv
results = [fields[1:] for fields in csv.reader(open("temp_data_01.csv", newline=''))]
# write to database
for row in results:
  if row:
      cursor.execute("""insert into weather (state, state_code,
              year_text, year_code, avg_max_temp,  max_temp_count,
              max_temp_low, max_temp_high,
              heat_index, heat_index_count,
              heat_index_low, heat_index_high,
              heat_index_coverage) values(?,?,?,?,?,?,?,?,?,?,?,?,?)""", row)
conn.commit()

"""# 23.4 Making database handling easier with an ORM

## 23.4.1 SQLAlchemy
"""

from sqlalchemy import create_engine, select, MetaData, Table, Column, Integer, String
from sqlalchemy.orm import sessionmaker

dbPath = 'datafile2.db'
engine = create_engine('sqlite:///%s' % dbPath)
metadata = MetaData()
people  = Table('people', metadata,
                Column('id', Integer, primary_key=True),
                Column('name', String),
                Column('count', Integer),
               )
Session = sessionmaker(bind=engine)
session = Session()
metadata.create_all(engine)

people_ins = people.insert().values(name='Bob', count=1)
str(people_ins)

session.execute(people_ins)

session.commit()

session.execute(people_ins, [
    {'name': 'Jill', 'count':15},
    {'name': 'Joe', 'count':10}
])

session.commit()
people_query = select(people)
result = session.execute(people_query)
for row in result:
    print(row)

result = session.execute(select(people).where(people.c.name == 'Jill'))
for row in result:
    print(row)

result = session.execute(people.update().values(count=20).where (people.c.name == 'Jill'))
session.commit()
result = session.execute(select(people).where(people.c.name == 'Jill'))
for row in result:
    print(row)

"""### Mapping table objects to classes"""

from sqlalchemy.orm import declarative_base
Base = declarative_base()
class People(Base):
    __tablename__ = "people"
    id = Column(Integer, primary_key=True)
    name = Column(String)
    count = Column(Integer)

results = session.query(People).filter_by(name='Jill')
for person in results:
    print(person.id, person.name, person.count)

new_person = People(name='Jane', count=5)
session.add(new_person)
session.commit()
results = session.query(People).all()
for person in results:
    print(person.id, person.name, person.count)

jill = session.query(People).filter_by(name='Jill').first()
jill.name

jill.count = 22
session.add(jill)
session.commit()
results = session.query(People).all()
for person in results:
    print(person.id, person.name, person.count)

jane = session.query(People).filter_by(name='Jane').first()
session.delete(jane)
session.commit()
jane = session.query(People).filter_by(name='Jane').first()
print(jane)

"""### Try This: Using an ORM
Using the database from earlier, write an SQLAlchemy class to map to the data table, and use it to read the records from the table.
"""



# @title
from sqlalchemy import create_engine, select, MetaData, Table, Column, Integer, String, Float
from sqlalchemy.orm import sessionmaker
dbPath = 'datafile.db'
engine = create_engine('sqlite:///%s' % dbPath)
metadata = MetaData()
Session = sessionmaker(bind=engine)
session = Session()
metadata.create_all(engine)
weather  = Table('weather', metadata,
                Column('id', Integer, primary_key=True),
                Column("state", String),
                Column("state_code", String),
                Column("year_text", String ),
                Column("year_code", String),
                Column("avg_max_temp", Float),
                Column("max_temp_count", Integer),
                Column("max_temp_low", Float),
                Column("max_temp_high", Float),
                Column("heat_index", Float),
                Column("heat_index_count", Integer),
                Column("heat_index_low", Float),
                Column("heat_index_high", Float),
                Column("heat_index_coverage", String)
                )
Session = sessionmaker(bind=engine)
session = Session()
result = session.query(weather).all()
for row in result:
    print(row)

"""## 23.4.2 Using Alembic for database schema changes"""

! rm -rf alembic/

! pip install alembic
! alembic init alembic

# This cell will update the alembic.ini file

! sed -i 's/driver:\/\/user:pass@localhost\/dbname/sqlite:\/\/\/datafile.db/' alembic.ini

# This cell creates the first revision script
result = ! alembic revision -m "create an address table"
filename= result[0].replace('Generating ', "").replace(" ...  done","")
version = filename.split("/")[-1].split("_")[0]

# This cell updates the revision script's upgrade() and downgrade() functions
upgrade_cmd = """def upgrade() -> None:
    op.create_table(
        'address',
        sa.Column('id', sa.Integer, primary_key=True),
        sa.Column('address', sa.String(50), nullable=False),
        sa.Column('city', sa.String(50), nullable=False),
        sa.Column('state', sa.String(20), nullable=False),
    )
"""
downgrade_cmd = """def downgrade() -> None:
    op.drop_table('address')"""

version_file = open(filename).read()
version_file = version_file.replace("""def upgrade() -> None:
    pass""", upgrade_cmd)
version_file = version_file.replace("""def downgrade() -> None:
    pass""", downgrade_cmd)
print(version_file)

open(filename, "w").write(version_file)

for table in metadata.sorted_tables:
    print(table.name)

! alembic upgrade head

metadata.sorted_tables

Session = sessionmaker(bind=engine)
session = Session()

metadata.reflect(engine)
metadata.tables.keys()
session.commit()

! alembic downgrade -1

for table in metadata.sorted_tables:
    print(table.name)

"""# 23.6 key:value stores with Redis"""

!pip install redis

"""### NOTE: You must create an account at redis.io or on another redis server for the examples to work properly.

Be sure to use the correct hostname and password for your account in cell below.
"""

import redis

r = redis.Redis(
    # set your host here
    host='',
    port=10032,
    # set your password below
    password='')

"""#### Basic operations"""

r.keys()

"""#### Array operations"""

r.set('a_key', 'my value')

r.keys()

v = r.get('a_key')
v

r.incr('counter')

r.get('counter')

r.incr('counter')

r.get('counter')

r.rpush("words", "one")

r.rpush("words", "two")

r.lrange("words", 0, -1)

r.rpush("words", "three")

r.lrange("words", 0, -1)

r.llen("words")

r.lpush("words", "zero")

r.lrange("words", 0, -1)

r.lrange("words", 2, 2)

r.lindex("words", 1)

r.lindex("words", 2)

"""### Expiration of values"""

r.setex("timed", 10,  "10 seconds")

r.pttl("timed")

r.pttl("timed")

b"timed" in r.keys()

"""### Quick Check: Uses of Key:Value stores
What sorts of data and applications would benefit most from a key:value store like Redis?

* Quick lookup of data
* Caching

# 23.7 Documents in MongoDB
"""

! pip install pymongo

"""### NOTE: you must have an account at mongondb.net or on another Mongo server for this code to work properly.

You may also have to authorize Access from Anywhere to connect to your DB.
"""

from pymongo import MongoClient
client = MongoClient(host='*** connection string here ***')   #A

import datetime
a_document = {'name': 'Jane',
              'age': 34,
              'interests': ['Python', 'databases', 'statistics'],
              'date_added': datetime.datetime.now()
}
db = client.my_data     #A
collection = db.docs   #B
result = collection.find_one()  #C
db.list_collection_names()

collection.insert_one(a_document)

collection.find_one()    #A

from bson.objectid import ObjectId

###----->>>> use ObjectId from cell above in code below

collection.find_one({"_id":ObjectId('674933fd4b145489056d9af8')})  #B

# use ObjectId from above in code below
collection.update_one({"_id":ObjectId('674933fd4b145489056d9af8')}, {"$set": {"name":"Ann"}})       #C

# use ObjectId from above in code below
collection.find_one({"_id":ObjectId('66f616d8b15e1d493ca8b8d0')})

# use ObjectId from above in code below
collection.replace_one({"_id":ObjectId('674933fd4b145489056d9af8')}, {"name":"Maria"})                 #D

# use ObjectId from above in code below
collection.find_one({"_id":ObjectId('674933fd4b145489056d9af8')})

# use ObjectId from above in code below
collection.delete_one({"_id":ObjectId('674933fd4b145489056d9af8')}) #E

collection.find_one()

db.list_collection_names()

collection.drop()
db.list_collection_names()

"""###Quick Check: Uses of MONGODB
Thinking back over the various data samples you’ve seen so far and other types of data in your experience, which do you think would be well suited to being stored in a database like MongoDB? Would others clearly not be suited, and if so, why not?

#### Discussion
Data that comes in large and/or more loosely organized chunks is suited to MongoDB, such as the contents of a web page or document.

Data with a specific structure is better suited to relational data. The weather data you've seen is a good example.

# Lab 23 Create a database

This is an open-ended challenge, so there is no “official” answer provided.
"""

